{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright 2023 LLM-Info (?????????????????????)\n",
    " *\n",
    " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    " * you may not use this file except in compliance with the License.\n",
    " * You may obtain a copy of the License at\n",
    " *\n",
    " *    http://www.apache.org/licenses/LICENSE-2.0\n",
    " *\n",
    " * Unless required by applicable law or agreed to in writing, software\n",
    " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    " * See the License for the specific language governing permissions and\n",
    " * limitations under the License.\n",
    " '''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b0435cb",
   "metadata": {},
   "source": [
    "# Generating Consistent and High Quality Infoboxes with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3839a6-9146-4f60-b74b-19abbc24278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import ast  # for converting embeddings saved as strings back to arrays\n",
    "import openai  # for calling the OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "\n",
    "\n",
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "from config import *\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c15f9",
   "metadata": {},
   "source": [
    "# Vector Database\n",
    "\n",
    "As input, we get raw Wikipedia text. As output, we will get the most similar infobox template.\n",
    "\n",
    "NOTE: do we want to structure the template as a bunch of fields or in proper format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8c713-c8a9-47dc-85a4-871ee1395566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search function - replace with vdb function\n",
    "def fake_vdb(\n",
    "    query: str,\n",
    "    templates: list,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 1\n",
    "):\n",
    "    '''\"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = openai.Embedding.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n], relatednesses[:top_n]'''\n",
    "    return templates[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ff4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"./QueryPipeline/\")\n",
    "\n",
    "collection = client.get_collection(name=\"infoboxes\")\n",
    "\n",
    "langchain_chroma = Chroma(\n",
    "    client=client,\n",
    "    collection_name=\"infoboxes\",\n",
    "    embedding_function=SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\"),\n",
    ")\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919bb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_template_from_vdb(query):\n",
    "    template = langchain_chroma.similarity_search_with_score(query)\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f2ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_template_from_object(template):\n",
    "    template = template[0].metadata['source'] # extract the infobox template\n",
    "    template = template[template.index(\"Infobox_\"):] # remove random seo stuff\n",
    "\n",
    "    # construct template consistent with wikipedia's format\n",
    "    template = template.split(' ')\n",
    "    template_string = \"{{\" + template[0] + \"\\n\"\n",
    "    for field in template[1:]:\n",
    "        template_string += f'| {field} = \\n'\n",
    "    template_string += \"}}\"\n",
    "    return template_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c960637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "query = \"\"\"\n",
    "Star Wars comics have been produced by various comic book publishers since the debut of the 1977 film Star Wars.[a] Marvel Comics launched its original series in 1977, beginning with a six-issue comic adaptation of the film and running for 107 issues, including an adaptation of The Empire Strikes Back. Marvel also released an adaptation of Return of the Jedi and spin-offs based on Droids and Ewoks. A self-titled comic strip ran in American newspapers between 1979 and 1984. Blackthorne Publishing released a three-issue run of 3-D comics from 1987 to 1988.\n",
    "\n",
    "Dark Horse Comics published the limited series Dark Empire in 1991, and ultimately produced over 100 Star Wars titles, including Tales of the Jedi (1993–1998), X-wing: Rogue Squadron (1995–1998), Republic (1998–2006), Tales (1999–2005), Empire (2002–2006), Knights of the Old Republic (2006–2010), and Legacy (2006–2010), as well as manga adaptations of the original film trilogy and the 1999 prequel The Phantom Menace.\n",
    "\n",
    "The Walt Disney Company acquired Marvel in 2009 and Lucasfilm in 2012, and the Star Wars comics license returned to Marvel in 2015. Several new series were launched, including Star Wars, Star Wars: Darth Vader, and Doctor Aphra. In 2017, IDW Publishing launched the anthology series Star Wars Adventures. In 2022, Dark Horse resumed publishing new Star Wars comics and graphic novels.\n",
    "\"\"\"\n",
    "retrieve_template_from_vdb(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183b58a",
   "metadata": {},
   "source": [
    "# LLM Querying\n",
    "\n",
    "As input, we provide the raw Wikipedia text and the infobox template. As output, we receive the generated infobox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f45cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formulate_query(\n",
    "    article: str,\n",
    "    infobox_template: str\n",
    ") -> str:\n",
    "    introduction = \"Your task is to fill out a Wikipedia infobox. Below, you are given some context text and the infobox template.\\n\"\n",
    "    question = f\"\\n\\n Context text: {article}\\n\\n Infobox Template: {infobox_template} \\n\\n\"\n",
    "    end = 'Fill out the Wikipedia infobox. Feel free to add any fields that you think would be important to know. Remember, keep the infobox concise, accurate, and of good quality.'\n",
    "    return introduction + question + end\n",
    "\n",
    "def api_call(message, model: str = GPT_MODEL):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return response_message\n",
    "\n",
    "def ask(\n",
    "    article: str,\n",
    "    infobox_template: str,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 4096 - 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = formulate_query(article, infobox_template)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    \n",
    "    reply = 'lol' #api_call(message, model)\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaad38f",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ea455",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\"\"\"Halley's Comet, Comet Halley, or sometimes simply Halley, officially designated 1P/Halley, is a short-period comet visible from Earth every 75–79 years.[1] Halley is the only known short-period comet that is regularly visible to the naked eye from Earth, and thus the only naked-eye comet that can appear twice in a human lifetime.[15] It last appeared in the inner parts of the Solar System in 1986 and will next appear in mid-2061.\n",
    "\n",
    "Halley's periodic returns to the inner Solar System have been observed and recorded by astronomers around the world since at least 240 BC. But it was not until 1705 that the English astronomer Edmond Halley understood that these appearances were re-appearances of the same comet. As a result of this discovery, the comet is named after Edmond Halley.[16]\n",
    "\n",
    "During its 1986 visit to the inner Solar System, Halley's Comet became the first comet to be observed in detail by spacecraft, providing the first observational data on the structure of a comet nucleus and the mechanism of coma and tail formation.[17][18] These observations supported a number of longstanding hypotheses about comet construction, particularly Fred Whipple's \"dirty snowball\" model, which correctly predicted that Halley would be composed of a mixture of volatile ices—such as water, carbon dioxide, ammonia, and dust. The missions also provided data that substantially reformed and reconfigured these ideas; for instance, it is now understood that the surface of Halley is largely composed of dusty, non-volatile materials, and that only a small portion of it is icy.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221eddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in articles:\n",
    "    # classification\n",
    "    template = retrieve_template_from_vdb(article)\n",
    "    for t in template:\n",
    "        print(t)\n",
    "\n",
    "    num = int(input('which one?'))\n",
    "    template = retrieve_template_from_object(template[num])\n",
    "\n",
    "    # generation\n",
    "    infobox = ask(article, template, print_message=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd2c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
